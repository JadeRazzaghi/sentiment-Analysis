{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"reviewerID\": \"A1E5ZR1Z4OQJG\", \"asin\": \"1495329321\", \"reviewerName\": \"Pure Jonel \\\"Pure Jonel\\\"\", \"helpful\": [0, 0], \"reviewText\": \"Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\", \"overall\": 4.0, \"summary\": \"An amazing first novel\", \"unixReviewTime\": 1396137600, \"reviewTime\": \"03 30, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file=\"/Users/jaderazzaghi/Desktop/NLP/reviews.json\"\n",
    "with open(file)as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#we want the review text:\n",
    "with open (file)as f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        print(review['reviewText'])#just the review text part of json file\n",
    "        print(review['overall'])#score of the review\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we just want text and score so to merge them:\n",
    "reviews=[]\n",
    "with open(file)as f:\n",
    "    for lines in f:\n",
    "        review=json.loads(lines)\n",
    "        reviews.append((review['reviewText'],review['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!', 4.0)\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#check if we created a good file:\n",
    "print(reviews[5])\n",
    "print(reviews[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make it neat we create a class:\n",
    "class Sentiment:\n",
    "    neg='NEGATIVE'\n",
    "    pos='POSITIVE'\n",
    "    neu='NEUTRAL'\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text=text\n",
    "        self.score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.neg\n",
    "        elif self.score==3:\n",
    "            return Sentiment.neu\n",
    "        else:\n",
    "            return Sentiment.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 \n",
      "\n",
      "For me personally it's the most disappointing book I have ready re: Kay Scarpetta. I generally can't put a Cornwell book down, but I had to force myself to keep reading it. Hard to stay focused when half a book describes approximately 4-6 hours. \n",
      "\n",
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "reviews=[]\n",
    "with open(file)as f:\n",
    "    for lines in f:\n",
    "        review=json.loads(lines)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "        \n",
    "        \n",
    "print(reviews[5].score,'\\n')\n",
    "print(reviews[1].text,'\\n')\n",
    "print(reviews[1].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split our data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "training,test=train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "Oh this is an awful bookA delightful awful bookJust the sort of awful bookYour whole family will adoreMy daughters requested it so often from the library, I finally just bought a copy.\n"
     ]
    }
   ],
   "source": [
    "print(training[1].sentiment)\n",
    "print(training[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Cunningham mesmerizes with the thoughtful, elegant prose that is this book.  The reader becomes so close to its characters...the reader feels what these brothers feel.  Beautiful and tragic...a book that will stay with me for a long, long time.  Thank you again, Mr. Cunningham.  The Hours remains at the top of my list and The Snow Queen is another gift to your readers.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we split the whole file we need to have our train and test (including text for x and labels for y)\n",
    "train_X=[x.text for x in training]\n",
    "train_y=[x.sentiment for x in training]\n",
    "test_X=[x.text for x in test]\n",
    "test_y=[x.sentiment for x in test]\n",
    "train_y[0]\n",
    "test_X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now turn the train and test into vectors using BOW:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "train_xvector=cv.fit_transform(train_X)\n",
    "test_xvector=cv.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])\n",
    "print(train_xvector[0]. toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traing our model:\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_xvector, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets do prediction\n",
    "test_X[0]\n",
    "clf_svm.predict(test_xvector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now try with other models:\n",
    "#1Decision Tree:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_DT=DecisionTreeClassifier()\n",
    "clf_DT.fit(train_xvector, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT.predict(test_xvector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#clf_NB=GaussianNB()\n",
    "#clf_NB.fit(train_xvector, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log=LogisticRegression()\n",
    "clf_log.fit(train_xvector, train_y)\n",
    "clf_log.predict(test_xvector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n",
      "0.7636363636363637\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "#let's evaluate the models:This is mean accuracy score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(clf_svm.score(test_xvector, test_y))\n",
    "print(clf_DT.score(test_xvector, test_y))\n",
    "print(clf_log.score(test_xvector, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91319444, 0.22222222, 0.21052632])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Measure F1score:\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, clf_svm.predict(test_xvector), average=None, labels=[Sentiment.pos, Sentiment.neg, Sentiment.neu])\n",
    "#so really hi 91 for pos, but trashy for the neg and neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86865149, 0.06896552, 0.1       ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, clf_DT.predict(test_xvector), average=None,labels=[Sentiment.pos, Sentiment.neg, Sentiment.neu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91370558, 0.1       , 0.12244898])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, clf_log.predict(test_xvector), average=None,labels=[Sentiment.pos, Sentiment.neg, Sentiment.neu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so now we need to fix this issue:\n",
    "train_y.count(Sentiment.pos)# so we have alot of pos in our y train so we need to balance our pos&neg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
